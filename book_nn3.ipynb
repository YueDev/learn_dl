{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cfa596689b5ecd1",
   "metadata": {},
   "source": [
    "## 用numpy写一个神经网络实现MINST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "51512cf286b9b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e56298674ebf21",
   "metadata": {},
   "source": [
    "利用pytorch下载的数据集，稍后会转换成ndarray给numpy使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d8351ebe2c9a3c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定函数的返回类型，方便IDE进行提示\n",
    "# def get_data() -> tuple[np.ndarray, np.ndarray]:\n",
    "# 不写返回类型也行，一般函数写的越简单越好\n",
    "def get_data():\n",
    "    training_data = datasets.MNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor()\n",
    "    )\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor()\n",
    "    )\n",
    "    tr = training_data.data / 255\n",
    "    te = training_data.targets\n",
    "    return tr.numpy(), te.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a8438fae048840",
   "metadata": {},
   "source": [
    "初始化网络，输入是应该是28*28=784 \n",
    "第一层输出50， 第二层输出100\n",
    "最后一层即第三层输出10个数，代表结果，输出函数可以用softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a5e3c7f1c73a5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(size_x):\n",
    "    nn = {\n",
    "        'w1': np.random.randn(size_x, 50),\n",
    "        #这里用rand(50)也行，加法的广播机制\n",
    "        'b1': np.random.randn(1, 50), \n",
    "\n",
    "        'w2': np.random.randn(50, 100),\n",
    "        'b2': np.random.randn(1, 100),\n",
    "\n",
    "        'w3': np.random.randn(100, 10),\n",
    "        'b3': np.random.randn(1, 10),\n",
    "    }\n",
    "    return nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f014c6e0e15c4",
   "metadata": {},
   "source": [
    "激活函数，输出函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "34a604c7152d8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    c = np.max(x)\n",
    "    exp_a = np.exp(x - c) # 减去c是为了防止溢出\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e18c6063ab0a8",
   "metadata": {},
   "source": [
    "正向运行网络，推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2f1ce764a534eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(nn, x):\n",
    "    w1, w2, w3 = nn['w1'], nn['w2'], nn['w3'] \n",
    "    b1, b2, b3 = nn['b1'], nn['b2'], nn['b3']\n",
    "    \n",
    "    a1 = x.dot(w1) + b1\n",
    "    y1 = sigmoid(a1)\n",
    "    \n",
    "    a2 = y1.dot(w2) + b2\n",
    "    y2 = sigmoid(a2)\n",
    "    \n",
    "    a3 = y2.dot(w3) + b3\n",
    "    y3 = softmax(a3)\n",
    "    \n",
    "    return y3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9425d3883b427c",
   "metadata": {},
   "source": [
    "运行一次网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "38fe5761e164d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.12, 0.  , 0.83, 0.  , 0.  , 0.05, 0.  ]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = get_data()\n",
    "i = np.random.randint(60000)\n",
    "x = data[i].reshape(1, 28 * 28)\n",
    "t_index = labels[i]\n",
    "nn = init_network(x.size)\n",
    "y = forward(nn, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b579bd8d3b7d548",
   "metadata": {},
   "source": [
    "接下来，定义两种损失函数, 这里增加了批量size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "958519e6028a7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均方误差 输出与目标的差的平方和，除以2\n",
    "def mean_square_error(y, t):\n",
    "    batch_size = y.shape[0]\n",
    "    return 0.5 * np.sum((y - t) ** 2) / batch_size\n",
    "\n",
    "# 交叉熵误差: 目标*loge(y)的和的负数 这个经常与sigmoid激活函数同时使用\n",
    "def cross_entropy_error(y, t):\n",
    "    # 由于loge(0)是负无穷大-inf，计算机无法继续之后的运算\n",
    "    # 所以给输入增加一个微小的数，并且不影响结果\n",
    "    delta = 1e-7\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + delta)) / batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f947b6d30c2605",
   "metadata": {},
   "source": [
    "看一下两种损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5916cf2a6cd3d1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "y = [[0.   0.   0.   0.12 0.   0.83 0.   0.   0.05 0.  ]]\n",
      "e1 = 0.802181\n",
      "e2 = 0.583236\n"
     ]
    }
   ],
   "source": [
    "t = np.zeros(10)\n",
    "t[int(t_index)] = 1\n",
    "\n",
    "\n",
    "\n",
    "e1 = mean_square_error(y, t)\n",
    "e2 = cross_entropy_error(y, y)\n",
    "\n",
    "# 设置np的打印选项：精度最大为小数点后2位，不用科学计数法\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "print('t =', t)\n",
    "print('y =', y)\n",
    "print(f'e1 = {e1:5f}')\n",
    "print(f'e2 = {e2:5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9040019",
   "metadata": {},
   "source": [
    "接下来看一看损失函数的批量处理是否正确 每一个损失函数的维度为10，总共100个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ee76e397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_test e1: 0.4985116597049505\n",
      "batch_test e2: 2.746850291489507\n"
     ]
    }
   ],
   "source": [
    "# 生成一个1000 * 10 的targets，每一列的元素是10个，其中一个为1，其余为0，与上边手写一样\n",
    "t_test = np.zeros((1000, 10))\n",
    "r_indices = np.arange(1000)\n",
    "c_indices = np.random.choice(10, 1000)\n",
    "c_indices\n",
    "t_test[r_indices, c_indices] = 1\n",
    "\n",
    "# y也是1000 * 10， 每一列的输出经过softmax处理，更真实了，\n",
    "# 这里softmax没有做批量处理，所以用了循环\n",
    "y_test = np.random.normal(0, 1, (1000, 10))\n",
    "r_t_indices = np.arange(1000)\n",
    "\n",
    "for i in range(1000):\n",
    "    y_test[i] = softmax(y_test[i])\n",
    "    \n",
    "e1 = mean_square_error(y_test, t_test)\n",
    "print('batch_test e1:', e1)\n",
    "e2 = cross_entropy_error(y_test, t_test)\n",
    "print('batch_test e2:', e2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
