{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4489a01",
   "metadata": {},
   "source": [
    "## 计算图的加法和乘法层的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211c272",
   "metadata": {},
   "source": [
    "#### 1. 简单的标量之间的计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8884d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算图的乘法层\n",
    "class MulLayer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = self.x * self.y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #乘法的反向是交换x y\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86347058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n",
      "2.2 110.00000000000001 200.0\n"
     ]
    }
   ],
   "source": [
    "# 测试乘法层 用书上苹果的案例 \n",
    "# y = x1 * x2 * x3\n",
    "x1 = 100  # 苹果单价\n",
    "x2 = 2    # 苹果个数\n",
    "x3 = 1.1  # 0.1的消费税\n",
    "\n",
    "\n",
    "# 第一层 苹果单价*个数 \n",
    "# 第二层 第一层的输出*税\n",
    "\n",
    "layer1 = MulLayer()\n",
    "layer2 = MulLayer()\n",
    "\n",
    "# forward\n",
    "o1 = layer1.forward(x1, x2)\n",
    "o2 = layer2.forward(o1, x3)\n",
    "print(f'{o2}')\n",
    "# o2就是x1 * x2 * x3\n",
    "\n",
    "# backward\n",
    "d = 1.0\n",
    "do1, d3 = layer2.backward(d)\n",
    "d1, d2 = layer1.backward(do1)\n",
    "print(d1, d2, d3)\n",
    "\n",
    "# d1/d2/d3表示x1/x2/x3增大1的话，输出y增大多少\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a270ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算图的加法层\n",
    "# 加法层比较简单，由于反向是把d直接传递出去，因此不需要存储x和y\n",
    "class AddLayer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        return x + y\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout, dout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b82459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "2.2 110.00000000000001 3.3000000000000003 165.0 650\n"
     ]
    }
   ],
   "source": [
    "# 测试加法层, 用书上苹果和橘子的案例\n",
    "# (苹果个数*苹果单价 + 橘子个数*橘子单价)*消费税=最终价\n",
    "\n",
    "x1 = 100  # 苹果单价\n",
    "x2 = 2    # 苹果个数\n",
    "x3 = 150  # 橘子单价\n",
    "x4 = 3    # 橘子个数\n",
    "x5 = 1.1  # 税\n",
    "\n",
    "layer1 = MulLayer() # 计算苹果总价\n",
    "layer2 = MulLayer() # 计算橘子总价\n",
    "layer3 = AddLayer() # 计算苹果+橘子总价\n",
    "layer4 = MulLayer() # 计算税后价格，即最终价格\n",
    "\n",
    "# forward 计算总价\n",
    "o1 = layer1.forward(x1, x2)\n",
    "o2 = layer2.forward(x3, x4)\n",
    "o3 = layer3.forward(o1, o2)\n",
    "o4 = layer4.forward(o3, x5)\n",
    "print(o4)\n",
    "\n",
    "# backward 计算x1-x5每提升1，对输出的影响\n",
    "d = 1\n",
    "do4, d5 = layer4.backward(d)\n",
    "do31, do32 = layer3.backward(do4)\n",
    "d1, d2 = layer1.backward(do31)\n",
    "d3, d4 = layer2.backward(do32)\n",
    "print(d1, d2, d3, d4, d5)\n",
    "\n",
    "# 这里的5个输出应该对照书里的计算图(书138页/pdf163页)上的反向数值一致\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd5ffb",
   "metadata": {},
   "source": [
    "#### 2. 批量输入的计算图，输入是numpy的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c2e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1821153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 激活函数的实现\n",
    "# relu函数 这里的输入是numpy的数组, mask是bool的ndarray\n",
    "class Relu: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "   \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx\n",
    "\n",
    "# sigmoid.  y = 1 / (1 - exp(-x))  导数是：y(1 - y)\n",
    "\n",
    "class Sigmoid():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.out * (1 - self.out)\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f8291b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "(3, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "# affine 仿射层\n",
    "# 仿射变换指的是向量X经过矩阵的线性变化和平移之后的变化，Y = X.W + b\n",
    "# 这里对应网络里的每一层，和OPENGL里，坐标点的平移缩放其实是一样的...\n",
    "class Affine:\n",
    "    \n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forword(self, x):\n",
    "        self.x = x\n",
    "        dout = x.dot(self.W) + self.b\n",
    "        return dout\n",
    "    \n",
    "    def backword(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx\n",
    "    \n",
    "# 测试下affine层\n",
    "X = np.random.rand(10, 3)\n",
    "W = np.random.rand(3, 4)\n",
    "# 这里B用rand(1,4)也行，不过backword里需要保持维度：\n",
    "# np.sum(dout, axis=0, keepdims=True)\n",
    "# 直接rand(4)当作一维数组处理，利用广播机制也很好, 求和就不用保持维度了\n",
    "B = np.random.rand(4)\n",
    "\n",
    "nn = Affine(W, B)\n",
    "Y = nn.forword(X)\n",
    "dy = np.random.rand(*Y.shape)\n",
    "dx = nn.backword(dy)\n",
    "\n",
    "print(dx.shape)\n",
    "print(nn.dW.shape)\n",
    "print(nn.db.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "94c6dc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7780617432346744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.27040524, -0.79625005,  0.14783498,  0.16457343,  0.10539249,\n",
       "         0.10804391],\n",
       "       [ 0.2007824 ,  0.20766571,  0.08333587,  0.09106223, -0.77973081,\n",
       "         0.1968846 ],\n",
       "       [ 0.17556456,  0.15732324,  0.23592382,  0.09904414,  0.17601619,\n",
       "        -0.84387194],\n",
       "       [ 0.17254261,  0.16242822,  0.18695241,  0.22311431, -0.86915796,\n",
       "         0.12412039],\n",
       "       [-0.86654801,  0.22231232,  0.19972956,  0.10024882,  0.1041884 ,\n",
       "         0.2400689 ],\n",
       "       [ 0.2113994 ,  0.11970695,  0.21815751,  0.09804639, -0.86930177,\n",
       "         0.22199152],\n",
       "       [ 0.1281818 ,  0.29403868,  0.13237207,  0.11283784, -0.83542405,\n",
       "         0.16799365],\n",
       "       [-0.75196752,  0.1336352 ,  0.11152758,  0.19930312,  0.19748874,\n",
       "         0.1100129 ],\n",
       "       [ 0.22834334, -0.85624629,  0.15955736,  0.14428698,  0.15154098,\n",
       "         0.17251762],\n",
       "       [ 0.19681145, -0.79788198,  0.18449839,  0.15977553,  0.12086807,\n",
       "         0.13592855]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax 输出层的实现 这里附带了交叉熵误差\n",
    "class SoftmaxWithLoss:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    # 输出函数 批量操作\n",
    "    def softmax(self, x):\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        c = np.max(x, axis = 1, keepdims = True)\n",
    "        exp_a = np.exp(x - c) # 减去c是为了防止溢出\n",
    "        sum_exp_a = np.sum(exp_a, axis = 1, keepdims = True)\n",
    "        y = exp_a / sum_exp_a\n",
    "        return y\n",
    "    \n",
    "     \n",
    "    # 损失函数 \n",
    "    def cross_entropy_error(self, y, t):\n",
    "        # 由于loge(0)是负无穷大-inf，计算机无法继续之后的运算\n",
    "        # 所以给输入增加一个微小的数，并且不影响结果\n",
    "        delta = 1e-7\n",
    "        # 除以批量\n",
    "        batch_size = y.shape[0]\n",
    "        return -np.sum(t * np.log(y + delta)) / batch_size\n",
    "    \n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        self.y = self.softmax(x)\n",
    "        self.t = t\n",
    "        loss = self.cross_entropy_error(self.y, t)\n",
    "        return loss\n",
    "    \n",
    "    def backword(self, dout = 1): \n",
    "        dx = (self.y -self.t)\n",
    "        return dx\n",
    "    \n",
    "\n",
    "\n",
    "# 测试下SoftMax\n",
    "X = np.random.rand(10, 6)\n",
    "\n",
    "T = np.zeros_like(X)\n",
    "rand_indices = np.random.choice(T.shape[1], size=T.shape[0])\n",
    "row_indices = np.arange(T.shape[0])\n",
    "T[row_indices, rand_indices] = 1.0\n",
    "\n",
    "nn = SoftmaxWithLoss()\n",
    "loss = nn.forward(X, T)\n",
    "print(loss)\n",
    "nn.backword(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
